{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00_Pytorch_Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n",
      "True\n",
      "12.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)  # 检查版本\n",
    "print(torch.cuda.is_available())  # 检查 CUDA 是否可用\n",
    "print(torch.version.cuda) # 检查 CUDA 版本  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor value as a standard Python number\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7, 7])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector\n",
    "vector = torch.tensor([7,7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix\n",
    "MATRIX = torch.tensor([[7,8],\n",
    "                      [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5150, 0.4141, 0.5410, 0.8064],\n",
       "        [0.7783, 0.8867, 0.8876, 0.6967],\n",
       "        [0.7302, 0.0843, 0.1515, 0.6688]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creat a random tensor of size (3,4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image\n",
    "random_image_size_tensor = torch.rand(size = (224, 224, 3)) #height, width, color channals (R, G, B)\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size = (3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros*random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size = (3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5150, 0.4141, 0.5410, 0.8064],\n",
       "        [0.7783, 0.8867, 0.8876, 0.6967],\n",
       "        [0.7302, 0.0843, 0.1515, 0.6688]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones*random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Range of Tensors and Tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange() to create a tensor of values between 1 and 10\n",
    "one_to_ten = torch.arange(1, 11)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  4,  7, 10, 13, 16, 19])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_twenty_with_step3 = torch.arange(start = 1, end = 21, step = 3)\n",
    "one_to_twenty_with_step3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_ones = torch.ones_like(input = one_to_ten)\n",
    "ten_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Datatypes\n",
    "\n",
    "#### **NOTE:** Three big errors might occur:\n",
    "\n",
    "1. Tensors not right datatype;\n",
    "2. Tensors not rigth shape;\n",
    "3. Tensors not on the right devices;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype = torch.float32,  # What data type is the tensor (e.g. float32, float64, int8, etc.)\n",
    "                               device = \"cuda\", # What device is the tensor on (e.g. CPU, GPU)\n",
    "                               requires_grad = False # Whether to track gradients for this tensor during backpropagation\n",
    "                               )\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8346, 0.9210, 0.0199, 0.0638],\n",
       "        [0.1073, 0.7000, 0.5219, 0.9018],\n",
       "        [0.6178, 0.0630, 0.3304, 0.1656]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8346, 0.9210, 0.0199, 0.0638],\n",
      "        [0.1073, 0.7000, 0.5219, 0.9018],\n",
      "        [0.6178, 0.0630, 0.3304, 0.1656]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is stored on: cpu\n",
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Find out the details about the tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\")\n",
    "# Move tensor to GPU (if available)\n",
    "if torch.cuda.is_available():\n",
    "    some_tensor = some_tensor.to(\"cuda\")\n",
    "    print(f\"Device tensor is stored on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Tensors (tensor operations)\n",
    "\n",
    "#### Tensor operations includes:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n",
      "tensor([10, 20, 30])\n",
      "tensor([-9, -8, -7])\n",
      "tensor([0.1000, 0.2000, 0.3000])\n",
      "tensor([1, 4, 9])\n",
      "tensor([1, 0, 1])\n",
      "tensor([0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor_add10 = torch.add(tensor, 10)  # Add 10 to each element\n",
    "print(tensor_add10)\n",
    "tensor_mult10 = torch.mul(tensor, 10)  # Multiply each element by 10\n",
    "print(tensor_mult10) \n",
    "tensor_sub10 = torch.sub(tensor, 10)  # Subtract 10 from each element\n",
    "print(tensor_sub10)\n",
    "tensor_div10 = torch.div(tensor, 10)  # Divide each element by 10\n",
    "print(tensor_div10)\n",
    "tensor_square = torch.pow(tensor, 2)  # Square each element\n",
    "print(tensor_square)\n",
    "tensor_mod2 = torch.remainder(tensor, 2)  # Modulus of each element\n",
    "print(tensor_mod2)\n",
    "tensor_floor_div2 = torch.floor_divide(tensor, 2)  # Floor division of each element\n",
    "print(tensor_floor_div2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication\n",
    "\n",
    "#### Two main ways of performing mulitiplication in neural networks and deep learning:\n",
    "\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n",
      "tensor([[1, 2, 3]]) @ tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "Equals: tensor([[14]])\n",
      "Equals: tensor([[14]])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "print(tensor, \"*\", tensor)  # Element-wise multiplication\n",
    "print(f\"Equals: {tensor * tensor}\")\n",
    "\n",
    "# Matrix multiplication\n",
    "print(tensor.reshape(1, 3), \"@\" , tensor.reshape(3, 1))  # Matrix multiplication\n",
    "print(f\"Equals: {tensor.reshape(1, 3) @ tensor.reshape(3, 1)}\") # Matrix multiplication using @ operator\n",
    "print(f\"Equals: {torch.matmul(tensor.reshape(1, 3), tensor.reshape(3, 1))}\") # Matrix multiplication using torch.matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.reshape from (1, 3) to (3, 1) is equivalent to tensor.reshape(1, 3).T\n",
      "Original tensor: tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3]])\n",
      "tensor([[1, 2, 3]])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Reshape and transpose\n",
    "print(\"tensor.reshape from (1, 3) to (3, 1) is equivalent to tensor.reshape(1, 3).T\")\n",
    "print(\"Original tensor:\", tensor)\n",
    "print(tensor.reshape(3, 1).reshape(1, 3))\n",
    "print(tensor.reshape(3, 1).T)\n",
    "print(tensor.T) # Note: 1D tensors do not have a transpose operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Tensor:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Transposed 2D Tensor:\n",
      " tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Transpose a 2D tensor\n",
    "tensor_2d = torch.tensor([[1, 2, 3],\n",
    "                          [4, 5, 6]])   \n",
    "print(\"2D Tensor:\\n\", tensor_2d)\n",
    "print(\"Transposed 2D Tensor:\\n\", tensor_2d.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum, etc. (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0,100,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the maximum value\n",
    "max_value1 = torch.max(x)\n",
    "max_value2 = x.max()\n",
    "max_value1, max_value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the minimum value\n",
    "min_value1 = torch.min(x)\n",
    "min_value2 = x.min()\n",
    "min_value1, min_value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean value - note: the torch.mean() function requires a tensor of flot32 datatype to work\n",
    "mean_value1 = torch.mean(x.type(torch.float32))\n",
    "mean_value2 = x.type(torch.float32).mean()\n",
    "mean_value1, mean_value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "min_value1 = torch.sum(x)\n",
    "min_value2 = x.sum()\n",
    "min_value1, min_value2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the postional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the postion in tensor that has the minimum calue with argmin()\n",
    "# -> return index position of target tensor where the minimum value is located\n",
    "argmin_value = torch.argmin(x)\n",
    "argmin_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the postion in tensor that has the maximum calue with argmax()\n",
    "# -> return index position of target tensor where the maximum value is located\n",
    "argmax_value = torch.argmax(x)\n",
    "argmax_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), torch.Size([10]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "y = torch.arange(1., 11.)\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "y_reshaped = y.reshape(1, 10)  # Reshape to (1, 10)\n",
    "y_reshaped, y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "y_viewed = y.view(1, 10)  # View as (1, 10)\n",
    "y_viewed, y_viewed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing y_viewed changes y (because .view() returns a view of the original tensor)\n",
    "y_viewed[:, 0] = 5\n",
    "y_viewed, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  5.,  5.,  5.],\n",
       "         [ 2.,  2.,  2.,  2.],\n",
       "         [ 3.,  3.,  3.,  3.],\n",
       "         [ 4.,  4.,  4.,  4.],\n",
       "         [ 5.,  5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.,  6.],\n",
       "         [ 7.,  7.,  7.,  7.],\n",
       "         [ 8.,  8.,  8.,  8.],\n",
       "         [ 9.,  9.,  9.,  9.],\n",
       "         [10., 10., 10., 10.]]),\n",
       " torch.Size([10, 4]),\n",
       " tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "y_stacked = torch.stack([y, y, y, y], dim = 1)\n",
    "y_stacked, y_stacked.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before squeeze:\n",
      " tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\n",
      "Shape before squeeze: torch.Size([1, 10])\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "After squeeze:\n",
      " tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "Shape after squeeze: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze away single dimensions\n",
    "print(\"Before squeeze:\\n\", y_reshaped)\n",
    "print(\"Shape before squeeze:\", y_reshaped.shape)\n",
    "print(\"\\n----------------------------------------\\n\")\n",
    "y_squeezed = y_reshaped.squeeze()\n",
    "print(\"After squeeze:\\n\", y_squeezed)\n",
    "print(\"Shape after squeeze:\", y_squeezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous target: tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "previous shape: torch.Size([10])\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "After unsqueeze:\n",
      " tensor([[ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\n",
      "Shape after unsqueeze: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# Unsqueeze the extra dimension\n",
    "print(\"previous target:\", y_squeezed)\n",
    "print(\"previous shape:\", y_squeezed.shape)\n",
    "print(\"\\n----------------------------------------\\n\")\n",
    "y_unsqueezed = y_squeezed.unsqueeze(dim = 0)  # Add extra dimension at dim 0\n",
    "print(\"After unsqueeze:\\n\", y_unsqueezed)\n",
    "print(\"Shape after unsqueeze:\", y_unsqueezed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image tensor shape: torch.Size([3, 224, 224])\n",
      "Permuted image tensor shape: torch.Size([224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "# Permute the dimensions of a tensor\n",
    "image_tensor = torch.randn(3, 224, 224)  # Simulate an image tensor with (color channels, height, width)\n",
    "print(\"Original image tensor shape:\", image_tensor.shape)\n",
    "permuted_image_tensor = image_tensor.permute(1, 2, 0)  # Change to (height, width, color channels)\n",
    "print(\"Permuted image tensor shape:\", permuted_image_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (Selecting data from tensors)\n",
    "\n",
    "Indexing with PyTorch is similiar to indexing with Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
